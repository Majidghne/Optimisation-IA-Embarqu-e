# Optimisation d'IA Embarqu√©e : Classification Fashion-MNIST

Ce projet explore les strat√©gies d'optimisation pour le d√©ploiement de mod√®les de Deep Learning sur des syst√®mes aux ressources limit√©es (frugalit√© num√©rique). L'√©tude compare syst√©matiquement diff√©rentes architectures pour identifier le meilleur compromis entre pr√©cision, vitesse et consommation.

## üìå Probl√©matique & Objectif
* **Probl√©matique** : Comment concilier performance IA et ressources limit√©es des syst√®mes embarqu√©s ?
* **Objectif** : Identifier l'architecture optimale pour la classification sur mat√©riel contraint.

## üìä M√©thodologie
L'√©tude repose sur la comparaison de deux types d'architectures : les r√©seaux convolutifs (CNN) et les perceptrons multicouches (MLP).

* **Dataset** : Fashion-MNIST (70 000 images en niveaux de gris, 28x28 pixels).
* **Protocole de test** : √âvaluation de la classification selon trois sc√©narios :
    1. Images originales.
    2. Images reconstruites par Autoencodeur (AE).
    3. M√©lange d'images originales et reconstruites (Robustesse).
* **Optimisation** : Utilisation de la fonction d'activation **LeakyReLU** pour stabiliser l'apprentissage et am√©liorer la qualit√© de reconstruction par rapport au ReLU standard.

## üöÄ R√©sultats Cl√©s
L'analyse montre que le choix de la dimension latente optimale se situe √† **60**, offrant le meilleur compromis entre fid√©lit√© de reconstruction (SSIM √©lev√©) et compression.

### Comparaison des performances (Architecture MLP vs CNN)
| M√©trique | Classifieur CNN | Classifieur MLP | Gain |
| :--- | :--- | :--- | :--- |
| **Pr√©cision** | [cite_start]89 - 90%  | 88 - 89%  | -1%  |
| **Vitesse Entra√Ænement** | 156s (moyenne)  | 13s (moyenne)  | **x12.4 plus rapide**  |
| **Vitesse Inf√©rence** | 2.4s (moyenne)  | 0.73s (moyenne)  | **x3.3 plus rapide**  |

## üí° Conclusion
Pour un syst√®me embarqu√© utilisant le dataset Fashion-MNIST, l'architecture la plus rationnelle est un **classifieur MLP direct**. L'utilisation d'un Autoencodeur n'apporte pas de b√©n√©fice significatif pour la classification et g√©n√®re une surcharge computationnelle inutile pour le mat√©riel frugal.

## üõ†Ô∏è Configuration de test
* **Logiciels** : Python, Google Colab, Spyder.
* **Mat√©riel** : AMD Ryzen 3 3200U @ 2.60 GHz, 8 Go RAM.

## üõ†Ô∏è Installation et Utilisation

### Pr√©requis
* Python 3.8+
* Environnement virtuel (recommand√©)

### Installation
1. Clonez le d√©p√¥t :
   ```bash
   git clone [https://github.com/Majidghne/Optimisation-IA-Embarqu-e.git](https://github.com/Majidghne/Optimisation-IA-Embarqu-e.git)
   cd Optimisation-IA-Embarqu-e
   pip install -r requirements.txt
